---
title: "p8105_hw2_sl4655"
author: "Shuya Liu"
date: "October 2, 2019"
output: github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

# _Problem 1_

### Read and clean the Mr. Trash Wheel sheet

```{r trash_wheel_data_input, message = FALSE}
## Read in Mr. Trash Wheel data
trash_wheel_data <- 
  readxl::read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                     sheet = "Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  select(dumpster:homes_powered) %>%
  drop_na(dumpster) %>%
  mutate(sports_balls = round(sports_balls) %>% as.integer())
```

### Read and clean precipitation data for 2017 and 2018

```{r precipitaion}
precip_2017_data <- 
  readxl::read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                     sheet = "2017 Precipitation",
                     range = "A2:B14") %>%
  janitor::clean_names() %>%
  drop_na(total) %>%
  mutate(year = 2017)

precip_2018_data <-
  readxl::read_excel(path = "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
                     sheet = "2018 Precipitation",
                     range = "A2:B14") %>%
  janitor::clean_names() %>%
  drop_na(total) %>%
  mutate(year = 2018)
```

### Combine precipitation datasets

```{r combine}
precip_combine_data <-
  rbind(precip_2017_data, precip_2018_data) %>%
  select(year, month, precipitation = total) %>% 
  mutate(month = factor(month, labels = month.name))
```

```{r stats, include = FALSE}
## Descriptive Statistics
total_2017 = sum(with(precip_combine_data, subset(precipitation, year == 2017)))
total_2018 = sum(with(precip_combine_data, subset(precipitation, year == 2018)))
min_2017 = min(with(precip_combine_data, subset(precipitation, year == 2017)))
min_2018 = min(with(precip_combine_data, subset(precipitation, year == 2018)))
max_2017 = max(with(precip_combine_data, subset(precipitation, year == 2017)))
max_2018 = max(with(precip_combine_data, subset(precipitation, year == 2018)))
```

* **For precipitation data**:

  The dataset `precip_combine_data` contains `r dim(precip_combine_data)[1]` observations of `r dim(precip_combine_data)[2]` variables: `r colnames(precip_combine_data)`. The total precipitation for year 2017 is `r total_2017`(in). The total precipitation for year 2018 is `r total_2018`(in). The difference between the total amount of the two years is `r total_2018 - total_2017`(in). In year 2017, the smallest amount of precipitation `r min_2017`(in) occurred in `r subset(precip_combine_data, precipitation == min_2017 & year == 2017)$month`, and the largest amount of precipitation `r max_2017`(in) occurred in `r subset(precip_combine_data, precipitation == max_2017 & year == 2017)$month`. In year 2018, the smallest amount of precipitation `r min_2018`(in) occurred in `r subset(precip_combine_data, precipitation == min_2018 & year == 2018)$month`, and the largest amount of precipitation `r max_2018`(in) occurred in `r subset(precip_combine_data, precipitation == max_2018 & year == 2018)$month`.

* **For Mr. Trash Wheel data**:

The dataset `trash_wheel_data` contains `r dim(trash_wheel_data)[1]` observations of `r dim(trash_wheel_data)[2]` variables: `r colnames(trash_wheel_data)`, with `r sum(is.na(trash_wheel_data))` missing data. The data starts from `r min(trash_wheel_data$date)` to `r max(trash_wheel_data$date)`. To interpret the data, we take the first line as an example: on `r trash_wheel_data$date[1]`, dumpster `r trash_wheel_data$dumpster[1]` collected `r trash_wheel_data$weight_tons[1]` tons of trash with a volume of `r trash_wheel_data$volume_cubic_yards[1]` cubic yards. These trash were consisted of `r trash_wheel_data$plastic_bottles[1]` plastic bottles, `r trash_wheel_data$polystyrene[1]` polystyrene, `r trash_wheel_data$cigarette_butts[1]` cigarette butts, `r trash_wheel_data$glass_bottles[1]` glass bottles, `r trash_wheel_data$grocery_bags[1]` gorcery bags, `r trash_wheel_data$chip_bags[1]` chip bags, and `r trash_wheel_data$sports_balls[1]` sports balls. And the trash generated powers for `r trash_wheel_data$homes_powered[1]` homes. (Each ton of trash equates to on average 500 kilowatts of electricity.  An average household will use 30 kilowatts per day.)
  
The medians of plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls for each year are shown as below:
  
```{r echo = FALSE}
aggregate(
  cbind(plastic_bottles, polystyrene, cigarette_butts, glass_bottles, grocery_bags, chip_bags, sports_balls) ~ year, 
  data = trash_wheel_data, 
  median)
```

The total amount of weight(tons), and volume(cubic_yards), and homes powered for each year are shown as below:

```{r echo = FALSE}
aggregate(
  cbind(weight_tons, volume_cubic_yards, homes_powered) ~ year,
  data = trash_wheel_data,
  sum
)
```

# _Problem 2_

### Clean the data in pols-month.csv

```{r pols_month, message = FALSE}
pols_data <- 
  read_csv(file = "./data/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(col = mon, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = factor(month, labels = month.name),
         president = factor(prez_gop, levels = c(0,1), labels = c("dem", "gop"))) %>%
  select(year:day, president, everything(), -prez_dem, -prez_gop, -day)
```

### Clean the data in snp.csv

```{r snp, message = FALSE}
snp_data <- 
  read_csv(file = "./data/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  mutate(date = as.Date(date, "%m / %d / %y")) %>%
  separate(col = date, into = c("year", "month", "day"), sep = "-") %>%
  mutate(month = factor(month, labels = month.name)) %>%
  select(year, month, snp_close = close) %>%
  arrange(year, month)

```

### Tidy the unemployment data

```{r umemployment, message = FALSE}
unemploy_data <- 
  read_csv(file = "./data/fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(
    jan:dec, 
    names_to = "month",
    values_to = "unemploy_rate") %>%
  mutate(month = 
           factor(month, 
                  levels = c("jan", "feb", "mar", "apr", "may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"), 
                  labels = month.name),
         year = as.character(year))
```

###Join the datasets

```{r merge, massage = FALSE}
## First merge snp into pols
join1_data <- left_join(pols_data, snp_data, by = c("year", "month"))

## Next merge unemployment into the result
result_data <- left_join(join1_data, unemploy_data, by = c("year", "month"))
```

**pols-month data**:

The dataset `pols_data` contains `r dim(pols_data)[1]` observations of `r dim(pols_data)[2]` variables, with `r sum(is.na(pols_data))` missing data, related related to the number of national politicians who are democratic or republican at any given time from `r min(pols_data$year)` to `r max(pols_data$year)`:

  * The variable `president` contains two values: `dem` represents that the president was democratic on the associated date, and `gop` respresents that the president was republican on the associated date
  * The variables contain the names of `gov`, `sen`, `rep` represent the number of governers, senators, and representatives in each party on the associated date
  
**snp data**:

The dataset `snp_data` contains `r dim(snp_data)[1]` observations of `r dim(snp_data)[2]` variables, with `r sum(is.na(snp_data))` missing data, related to Standard & Poor’s stock market index from `r min(snp_data$year)` to `r max(snp_data$year)`:

  * The variable `snp_close` represents the closing values of the S&P stock index

**umployment data**:

The dataset `unemploy_data` contains `r dim(unemploy_data)[1]` observations of `r dim(unemploy_data)[2]` variables, with `r sum(is.na(unemploy_data))` missing data, related to the precentage of umemployment in each month from `r min(unemploy_data$year)` to `r max(unemploy_data$year)`:

  * The variable `unemploy_rate` represents the unemployment rate of the associated month

**resulting dataset**:

The dataset `result_data` contains `r dim(result_data)[1]` observations of `r dim(result_data)[2]` variables from `r min(result_data$year)` to `r max(result_data$year)`, with `r sum(is.na(result_data))` missing values. The variables are `r colnames(result_data)`.

# _Problem 3_

### Load and tidy the data

```{r name_data, message = FALSE}
name_data <- 
  read_csv(file = "./data/Popular_Baby_Names.csv") %>%
  janitor::clean_names()
```

Note that, although these data may seem fairly well formatted initially, the names of a categorical predictor and the case structure of string variables changed over time; you’ll need to address this in your data cleaning. Also, some rows seem duplicated, and these will need to be removed (hint: google something like “dplyr remove duplicate rows” to get started).

Produce a well-structured, reader-friendly table showing the rank in popularity of the name “Olivia” as a female baby name over time; this should have rows for ethnicities and columns for year. Produce a similar table showing the most popular name among male children over time.

Finally, for male, white non-hispanic children born in 2016, produce a scatter plot showing the number of children with a name (y axis) against the rank in popularity of that name (x axis).